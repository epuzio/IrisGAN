{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmGg6llvJu/m85sfmwyHwN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epuzio/IrisGAN/blob/main/IrisGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sDNadx8Xc2-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Sa2FV9RcRe6"
      },
      "outputs": [],
      "source": [
        "#@title Create TFRecord from video input { display-mode: \"form\", run: \"auto\" }\n",
        "from google.colab import drive #path to google drive\n",
        "drive.mount('/G', force_remount=True)\n",
        "gdir = '/G/MyDrive/'\n",
        "%cd $gdir\n",
        "\n",
        "#@markdown Include path to video from home Drive directory\n",
        "path_to_video = 'input_video' #@param {type:\"string\"}\n",
        "video_file_path = gdir + path_to_video\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create TFRecord from video input { display-mode: \"form\", run: \"auto\" }\n",
        "!pip install opencv-python-headless #installs cv2 in Colab\n",
        "import cv2, sys, os, math, glob, time, zipfile #all other packages are preinstalled\n",
        "\n",
        "\n",
        "def get_title(file_path):\n",
        "    '''\n",
        "    Helper function to split file path to get title of video\n",
        "    '''\n",
        "    return os.path.split(os.path.split(file_path)[1])[1].split('.')[0]\n",
        "\n",
        "def process_videos():\n",
        "    '''\n",
        "    Helper function to run detect_faces on single .mp4 input or on all videos in specified folder\n",
        "    '''\n",
        "\n",
        "    if os.path.isfile(sys.argv[2]):\n",
        "        detect_faces(sys.argv[2])\n",
        "    if os.path.isdir(sys.argv[2]):\n",
        "        for file in glob.glob(sys.argv[2] + \"/*\"):\n",
        "            print(\"Processing:\", file)\n",
        "            detect_faces(file)\n",
        "    else:\n",
        "        print(\"Invalid file path\")\n",
        "\n",
        "def crop_bounds(x, y, w, h, dim_x, dim_y, frame):\n",
        "    '''\n",
        "    Helper function to crop frames around faces to dimensions specified by dim_x, dim_y.\n",
        "    Extra logic added so that the crop stays within the bounds of the original image.\n",
        "    Dim_x and Dim_y are the x and y dimensions of the cropped frame\n",
        "    '''\n",
        "    center_x =  x + (w//2)\n",
        "    center_y =  y + (h//2)\n",
        "    top_x = center_x - (dim_x // 2)\n",
        "    top_y = center_y - (dim_y // 2)\n",
        "    bottom_x = center_x + (dim_x // 2)\n",
        "    bottom_y = center_y + (dim_y // 2)\n",
        "\n",
        "    if top_x < 0:\n",
        "        bottom_x -= top_x\n",
        "        top_x = 0\n",
        "    if top_y < 0:\n",
        "        bottom_y -= top_y\n",
        "        top_y = 0\n",
        "    if bottom_x > frame.shape[1]:\n",
        "        top_x -= (bottom_x - frame.shape[1])\n",
        "        bottom_x = frame.shape[1]\n",
        "    if bottom_y > frame.shape[0]:\n",
        "        top_y -= (bottom_y - frame.shape[0])\n",
        "        bottom_y = frame.shape[0]\n",
        "\n",
        "    cropped_frame = frame[top_y:bottom_y, top_x:bottom_x]\n",
        "    return cropped_frame\n",
        "\n",
        "def detect_faces(file_path, crop_frames = True, dim_x = 512, dim_y = 512):\n",
        "    '''\n",
        "    Uses cv2 CascadeClassifier to find all frames containing human faces,\n",
        "    Frames are output to local output_images folder. All images must be the same dimensions\n",
        "    for the GAN to work properly.\n",
        "    '''\n",
        "\n",
        "    video = cv2.VideoCapture(file_path)\n",
        "    fps = math.ceil(video.get(cv2.CAP_PROP_FPS))\n",
        "    kps = 1 #number of captures per second of film - 1 is every frame, 2 is every other frame, etc\n",
        "\n",
        "    if not video.isOpened():\n",
        "        print(\"Error opening video file\")\n",
        "        exit()\n",
        "\n",
        "    print(\"Video Dimensions:\", video.get(cv2.CAP_PROP_FRAME_WIDTH), \"x\" , video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    if(dim_x > video.get(cv2.CAP_PROP_FRAME_WIDTH) or dim_y > video.get(cv2.CAP_PROP_FRAME_HEIGHT)): #:pensive:\n",
        "        print(\"Error: cropped dimensions exceed the dimensions of the original video.\")\n",
        "        exit()\n",
        "\n",
        "\n",
        "    front_face_classifier = cv2.CascadeClassifier(\n",
        "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
        "    )\n",
        "\n",
        "    left_profile_classifier = cv2.CascadeClassifier(\n",
        "        cv2.data.haarcascades + \"haarcascade_profileface.xml\"\n",
        "    )\n",
        "\n",
        "    fc = 0\n",
        "    title = get_title(file_path)\n",
        "    print(\"File:\", title)\n",
        "    print(\"Frames:\", int(video.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "    start_time = time.time()\n",
        "    os.chdir(\"output_images\") #specify output directory of images\n",
        "    for _ in range(int(video.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        image_filename = f'{title}_frame{fc}.jpg'\n",
        "        read_frame_success, frame = video.read()\n",
        "\n",
        "        if fc % round(fps / kps) == 0:\n",
        "            if not read_frame_success:\n",
        "                break\n",
        "            gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "            #Left Profile:\n",
        "            left_profile = left_profile_classifier.detectMultiScale(\n",
        "                gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)\n",
        "            )\n",
        "            if len(left_profile) > 0:\n",
        "                for (x, y, w, h) in left_profile:\n",
        "                    if crop_frames:\n",
        "                        frame = crop_bounds(x, y, w, h, dim_x, dim_y, frame)\n",
        "                        frame = cv2.resize(frame, (256, 256))\n",
        "                    cv2.imwrite(image_filename, frame)\n",
        "\n",
        "            #Right profile\n",
        "            right_profile = left_profile_classifier.detectMultiScale( #flip image to check right profiles\n",
        "                cv2.flip(gray_image, 1), scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)\n",
        "            )\n",
        "            if len(right_profile) > 0:\n",
        "                for (x, y, w, h) in right_profile:\n",
        "                    if crop_frames:\n",
        "                        frame = crop_bounds(x, y, w, h, dim_x, dim_y, frame)\n",
        "                        frame = cv2.resize(frame, (256, 256))\n",
        "                    cv2.imwrite(image_filename, frame)\n",
        "\n",
        "            #Front face\n",
        "            front_face = front_face_classifier.detectMultiScale(\n",
        "                gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)\n",
        "            )\n",
        "            if len(front_face) > 0:\n",
        "                for (x, y, w, h) in front_face:\n",
        "                    if crop_frames:\n",
        "                        frame = crop_bounds(x, y, w, h, dim_x, dim_y, frame)\n",
        "                        frame = cv2.resize(frame, (256, 256))\n",
        "                    cv2.imwrite(image_filename, frame)\n",
        "        fc += 1\n",
        "        print(\"Outputting Frame:\", fc, end=\"\\r\")\n",
        "    print(\"Finished in:\", round((time.time() - start_time), 2), \"seconds.\")\n",
        "\n",
        "def remove_files():\n",
        "    '''\n",
        "    Removes images from output_images\n",
        "    '''\n",
        "    if len(sys.argv) == 2:\n",
        "        for img in os.listdir('output_images'):\n",
        "            os.remove(os.path.join(\"output_images\", img))\n",
        "    if len(sys.argv) == 3:\n",
        "        title = get_title(sys.argv[2])\n",
        "        for img in os.listdir('output_images'):\n",
        "            if title == img.split(\"_\")[0]:\n",
        "                os.remove(os.path.join(\"output_images\", img))\n",
        "\n",
        "def zip_files():\n",
        "    '''\n",
        "    Zips all images in output_images to a .zip file\n",
        "    '''\n",
        "    with zipfile.ZipFile(\"output_training_set.zip\", \"w\") as zipf:\n",
        "        for img in os.listdir(\"output_images\"):\n",
        "            zipf.write(os.path.join(\"output_images\", img), img)\n",
        "\n",
        "def make_training_set():\n",
        "    '''\n",
        "    Save all images in output_images to a .tfrecord file - this is an efficient way\n",
        "    to store a dataset for the GAN. Tensorflow is imported here as it takes a long time to import\n",
        "    and should only be imported when necessary.\n",
        "    '''\n",
        "    from tensorflow.io import TFRecordWriter, encode_jpeg\n",
        "    from tensorflow.train import Example, Features, Feature, BytesList\n",
        "\n",
        "    tfrecord_file_path = 'output.tfrecord'\n",
        "\n",
        "    if not (os.path.exists(\"output_training_set.zip\")):\n",
        "        zip_files()\n",
        "    count = 0\n",
        "    with TFRecordWriter(tfrecord_file_path) as writer:\n",
        "        with zipfile.ZipFile(\"output_training_set.zip\", \"r\") as zip_ref:\n",
        "            # Iterate over the files in the zip file\n",
        "            for file_name in zip_ref.namelist():\n",
        "                # Read the image from the zip file\n",
        "                image_data = zip_ref.read(file_name)\n",
        "\n",
        "                feature = {\n",
        "                    'image': Feature(bytes_list=BytesList(value=[image_data]))\n",
        "                }\n",
        "\n",
        "                example = Example(features=Features(feature=feature))\n",
        "                writer.write(example.SerializeToString()) #SerializeToString turns the example into a binary string\n",
        "                count += 1\n",
        "    print(f\"TFRecord file created from zip: {tfrecord_file_path}, {count} images written.\")\n",
        "\n",
        "def main():\n",
        "    if len(sys.argv) < 1:\n",
        "        print(\"ARG1: input video path as .mp4\")\n",
        "    else:\n",
        "        match sys.argv[1].split('.')[-1]:\n",
        "            case \"load\":\n",
        "                process_videos()\n",
        "            case \"clean\":\n",
        "                remove_files()\n",
        "            case \"zip\":\n",
        "                zip_files()\n",
        "            case \"tfr\":\n",
        "                make_training_set()\n",
        "            case \"help\":\n",
        "                print(\"To load single video: python3 detect.py load input_videos/title_of_video.mp4\")\n",
        "                print(\"To load multiple videos from file: python3 detect.py load input_videos\")\n",
        "                print(\"To clean all files: python3 detect.py clean\")\n",
        "                print(\"To clean files by title: python3 detect.py clean title\")\n",
        "                print(\"Make zip file from image set: python3 detect.py zip\")\n",
        "                print(\"Make tfrecord (for GAN): python3 detect.py tfr\")\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "9K1NxHmyffRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless #installs cv2 in Colab\n",
        "import cv2, sys, os, math, glob, time, zipfile #all other packages are preinstalled\n",
        "\n",
        "import cv2, sys, os, math, glob, time, zipfile\n",
        "\n",
        "def get_title(file_path):\n",
        "    '''\n",
        "    Helper function to split file path to get title of video\n",
        "    '''\n",
        "    return os.path.split(os.path.split(file_path)[1])[1].split('.')[0]\n",
        "\n",
        "def process_videos():\n",
        "    '''\n",
        "    Helper function to run detect_faces on single .mp4 input or on all videos in specified folder\n",
        "    '''\n",
        "\n",
        "    if os.path.isfile(sys.argv[2]):\n",
        "        detect_faces(sys.argv[2])\n",
        "    if os.path.isdir(sys.argv[2]):\n",
        "        for file in glob.glob(sys.argv[2] + \"/*\"):\n",
        "            print(\"Processing:\", file)\n",
        "            detect_faces(file)\n",
        "    else:\n",
        "        print(\"Invalid file path\")\n",
        "\n",
        "def crop_bounds(x, y, w, h, dim_x, dim_y, frame):\n",
        "    '''\n",
        "    Helper function to crop frames around faces to dimensions specified by dim_x, dim_y.\n",
        "    Extra logic added so that the crop stays within the bounds of the original image.\n",
        "    Dim_x and Dim_y are the x and y dimensions of the cropped frame\n",
        "    '''\n",
        "    center_x =  x + (w//2)\n",
        "    center_y =  y + (h//2)\n",
        "    top_x = center_x - (dim_x // 2)\n",
        "    top_y = center_y - (dim_y // 2)\n",
        "    bottom_x = center_x + (dim_x // 2)\n",
        "    bottom_y = center_y + (dim_y // 2)\n",
        "\n",
        "    if top_x < 0:\n",
        "        bottom_x -= top_x\n",
        "        top_x = 0\n",
        "    if top_y < 0:\n",
        "        bottom_y -= top_y\n",
        "        top_y = 0\n",
        "    if bottom_x > frame.shape[1]:\n",
        "        top_x -= (bottom_x - frame.shape[1])\n",
        "        bottom_x = frame.shape[1]\n",
        "    if bottom_y > frame.shape[0]:\n",
        "        top_y -= (bottom_y - frame.shape[0])\n",
        "        bottom_y = frame.shape[0]\n",
        "\n",
        "    cropped_frame = frame[top_y:bottom_y, top_x:bottom_x]\n",
        "    return cropped_frame\n",
        "\n",
        "def detect_faces(file_path, crop_frames = True, dim_x = 512, dim_y = 512):\n",
        "    '''\n",
        "    Uses cv2 CascadeClassifier to find all frames containing human faces,\n",
        "    Frames are output to local output_images folder. All images must be the same dimensions\n",
        "    for the GAN to work properly.\n",
        "    '''\n",
        "\n",
        "    video = cv2.VideoCapture(file_path)\n",
        "    fps = math.ceil(video.get(cv2.CAP_PROP_FPS))\n",
        "    kps = 1 #number of captures per second of film - 1 is every frame, 2 is every other frame, etc\n",
        "\n",
        "    if not video.isOpened():\n",
        "        print(\"Error opening video file\")\n",
        "        exit()\n",
        "\n",
        "    print(\"Video Dimensions:\", video.get(cv2.CAP_PROP_FRAME_WIDTH), \"x\" , video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    if(dim_x > video.get(cv2.CAP_PROP_FRAME_WIDTH) or dim_y > video.get(cv2.CAP_PROP_FRAME_HEIGHT)):\n",
        "        print(\"Error: cropped dimensions exceed the dimensions of the original video.\")\n",
        "        exit()\n",
        "\n",
        "\n",
        "    front_face_classifier = cv2.CascadeClassifier(\n",
        "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
        "    )\n",
        "\n",
        "    left_profile_classifier = cv2.CascadeClassifier(\n",
        "        cv2.data.haarcascades + \"haarcascade_profileface.xml\"\n",
        "    )\n",
        "\n",
        "    fc = 0\n",
        "    title = get_title(file_path)\n",
        "    print(\"File:\", title)\n",
        "    print(\"Frames:\", int(video.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "    start_time = time.time()\n",
        "    os.chdir(\"output_images\") #specify output directory of images\n",
        "    for _ in range(int(video.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        image_filename = f'{title}_frame{fc}.jpg'\n",
        "        read_frame_success, frame = video.read()\n",
        "\n",
        "        if fc % round(fps / kps) == 0:\n",
        "            if not read_frame_success:\n",
        "                break\n",
        "            gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "            #Left Profile:\n",
        "            left_profile = left_profile_classifier.detectMultiScale(\n",
        "                gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)\n",
        "            )\n",
        "            if len(left_profile) > 0:\n",
        "                for (x, y, w, h) in left_profile:\n",
        "                    if crop_frames:\n",
        "                        frame = crop_bounds(x, y, w, h, dim_x, dim_y, frame)\n",
        "                        frame = cv2.resize(frame, (256, 256))\n",
        "                    cv2.imwrite(image_filename, frame)\n",
        "\n",
        "            #Right profile\n",
        "            right_profile = left_profile_classifier.detectMultiScale( #flip image to check right profiles\n",
        "                cv2.flip(gray_image, 1), scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)\n",
        "            )\n",
        "            if len(right_profile) > 0:\n",
        "                for (x, y, w, h) in right_profile:\n",
        "                    if crop_frames:\n",
        "                        frame = crop_bounds(x, y, w, h, dim_x, dim_y, frame)\n",
        "                        frame = cv2.resize(frame, (256, 256))\n",
        "                    cv2.imwrite(image_filename, frame)\n",
        "\n",
        "            #Front face\n",
        "            front_face = front_face_classifier.detectMultiScale(\n",
        "                gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)\n",
        "            )\n",
        "            if len(front_face) > 0:\n",
        "                for (x, y, w, h) in front_face:\n",
        "                    if crop_frames:\n",
        "                        frame = crop_bounds(x, y, w, h, dim_x, dim_y, frame)\n",
        "                        frame = cv2.resize(frame, (256, 256))\n",
        "                    cv2.imwrite(image_filename, frame)\n",
        "        fc += 1\n",
        "        print(\"Outputting Frame:\", fc, end=\"\\r\")\n",
        "    print(\"Finished in:\", round((time.time() - start_time), 2), \"seconds.\")\n",
        "\n",
        "def remove_files():\n",
        "    '''\n",
        "    Removes images from output_images\n",
        "    '''\n",
        "    if len(sys.argv) == 2:\n",
        "        for img in os.listdir('output_images'):\n",
        "            os.remove(os.path.join(\"output_images\", img))\n",
        "    if len(sys.argv) == 3:\n",
        "        title = get_title(sys.argv[2])\n",
        "        for img in os.listdir('output_images'):\n",
        "            if title == img.split(\"_\")[0]:\n",
        "                os.remove(os.path.join(\"output_images\", img))\n",
        "\n",
        "def zip_files():\n",
        "    '''\n",
        "    Zips all images in output_images to a .zip file\n",
        "    '''\n",
        "    with zipfile.ZipFile(\"output_training_set.zip\", \"w\") as zipf:\n",
        "        for img in os.listdir(\"output_images\"):\n",
        "            zipf.write(os.path.join(\"output_images\", img), img)\n",
        "\n",
        "def make_training_set():\n",
        "    '''\n",
        "    Save all images in output_images to a .tfrecord file - this is an efficient way\n",
        "    to store a dataset for the GAN. Tensorflow is imported here as it takes a long time to import\n",
        "    and should only be imported when necessary.\n",
        "    '''\n",
        "    from tensorflow.io import TFRecordWriter, encode_jpeg\n",
        "    from tensorflow.train import Example, Features, Feature, BytesList\n",
        "\n",
        "    tfrecord_file_path = 'output.tfrecord'\n",
        "\n",
        "    if not (os.path.exists(\"output_training_set.zip\")):\n",
        "        zip_files()\n",
        "    count = 0\n",
        "    with TFRecordWriter(tfrecord_file_path) as writer:\n",
        "        with zipfile.ZipFile(\"output_training_set.zip\", \"r\") as zip_ref:\n",
        "            # Iterate over the files in the zip file\n",
        "            for file_name in zip_ref.namelist():\n",
        "                # Read the image from the zip file\n",
        "                image_data = zip_ref.read(file_name)\n",
        "\n",
        "                feature = {\n",
        "                    'image': Feature(bytes_list=BytesList(value=[image_data]))\n",
        "                }\n",
        "\n",
        "                example = Example(features=Features(feature=feature))\n",
        "                writer.write(example.SerializeToString()) #SerializeToString turns the example into a binary string\n",
        "                count += 1\n",
        "    print(f\"TFRecord file created from zip: {tfrecord_file_path}, {count} images written.\")\n",
        "\n",
        "def main():\n",
        "    if len(sys.argv) < 1:\n",
        "        print(\"ARG1: input video path as .mp4\")\n",
        "    else:\n",
        "        match sys.argv[1].split('.')[-1]:\n",
        "            case \"load\":\n",
        "                process_videos()\n",
        "            case \"clean\":\n",
        "                remove_files()\n",
        "            case \"zip\":\n",
        "                zip_files()\n",
        "            case \"tfr\":\n",
        "                make_training_set()\n",
        "            case \"help\":\n",
        "                print(\"To load single video: python3 detect.py load input_videos/title_of_video.mp4\")\n",
        "                print(\"To load multiple videos from file: python3 detect.py load input_videos\")\n",
        "                print(\"To clean all files: python3 detect.py clean\")\n",
        "                print(\"To clean files by title: python3 detect.py clean title\")\n",
        "                print(\"Make zip file from image set: python3 detect.py zip\")\n",
        "                print(\"Make tfrecord (for GAN): python3 detect.py tfr\")\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "kMpCmayKfORn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}